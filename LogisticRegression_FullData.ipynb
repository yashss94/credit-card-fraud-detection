{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression-FullData.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AohY2FyjHY4H",
        "colab_type": "code",
        "outputId": "01673bb4-5cc4-4ae5-d0f3-2c0529dc222b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Apr 25 20:36:32 2020\n",
        "\n",
        "@author: yash\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('creditcard.csv')\n",
        "\n",
        "X = dataset.iloc[:, 0:30].values\n",
        "Y = dataset.iloc[:, 30].values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25,shuffle = True, random_state = 42,  stratify = Y )\n",
        "C_values = [0.05, 0.1, 0.25, 0.5]\n",
        "max_bal_acc = 0\n",
        "best_c = 0\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "for c in C_values:\n",
        "  model = LogisticRegression(max_iter = 500, C = c)\n",
        "\n",
        "  model.fit(X_train, Y_train)\n",
        "\n",
        "  model.score(X_test, Y_test) \n",
        "\n",
        "  Y_pred = model.predict(X_test)\n",
        "\n",
        "  bal_acc = balanced_accuracy_score(Y_test, Y_pred)\n",
        "  if bal_acc > max_bal_acc:\n",
        "    max_bal_acc = bal_acc\n",
        "    best_c = c\n",
        "\n",
        "print(\"The maximum balaced accuracy acheived is: {}\".format(max_bal_acc))\n",
        "print(\"The best value of C is:{}\".format(best_c))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum balaced accuracy acheived is: 0.8088446074601294\n",
            "The best value of C is:0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O20Y32XrPZ6k",
        "colab_type": "text"
      },
      "source": [
        "As we have acheived a m maximum balanced accuracy of C, we will use that and try to experiment with different data splits to identify the best split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPlzZ0g_PkMz",
        "colab_type": "code",
        "outputId": "dbc66f5b-4f17-4577-fab3-bb1d4deef4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, accuracy_score\n",
        "\n",
        "train_time = []\n",
        "test_time = []\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "auc = []\n",
        "balanced = []\n",
        "f1 = []\n",
        "splits = []\n",
        "models = []\n",
        "roc = []\n",
        "pr = []\n",
        "conf_mat = []\n",
        "\n",
        "# for each split percent\n",
        "for split in range(10, 51, 10):\n",
        "    splits.append(split)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=split/100, shuffle = True, random_state=42, stratify=None)\n",
        "    # train\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "    start1 = dt.datetime.now()\n",
        "    model = LogisticRegression(max_iter = 500, C = best_c)\n",
        "    model.fit(X_train, Y_train)\n",
        "    models.append(model)\n",
        "    end1 = dt.datetime.now()\n",
        "    # test\n",
        "    start2 = dt.datetime.now()\n",
        "    Y_pred = model.predict(X_test)\n",
        "    print(classification_report(Y_test, Y_pred))\n",
        "    fpr, tpr, _ = roc_curve(Y_test, Y_pred)\n",
        "    roc.append([tpr, fpr])  # for roc curve\n",
        "    p, r, _ = precision_recall_curve(Y_test, Y_pred)\n",
        "    pr.append([p, r])   # for pr curve\n",
        "    cfm = confusion_matrix(Y_test, Y_pred)\n",
        "    print(cfm)\n",
        "    print(\"----------\")\n",
        "    conf_mat.append(cfm)   # for confusion matrix later\n",
        "    end2 = dt.datetime.now()\n",
        "    # score\n",
        "    train_time.append(end1 - start1)\n",
        "    test_time.append(end2 - start2)\n",
        "    accuracy.append(accuracy_score(Y_test, Y_pred))\n",
        "    precision.append(precision_score(Y_test, Y_pred))\n",
        "    recall.append(recall_score(Y_test, Y_pred))\n",
        "    auc.append(roc_auc_score(Y_test, Y_pred))\n",
        "    balanced.append(balanced_accuracy_score(Y_test, Y_pred))\n",
        "    f1.append(f1_score(Y_test, Y_pred))\n",
        "\n",
        "for i in range(len(train_time)):\n",
        "  print(\"----------\")\n",
        "  print(\"Logistic Regression at {}% split:\".format(splits[i]))\n",
        "  print(\"Accuracy score = {}\".format(accuracy[i]))\n",
        "  print(\"Precision score = {}\".format(precision[i]))\n",
        "  print(\"Recall score = {}\".format(recall[i]))\n",
        "  print(\"AUC_ROC score = {}\".format(auc[i]))\n",
        "  print(\"Balanced accuracy score = {}\".format(balanced[i]))\n",
        "  print(\"F1 score = {}\".format(f1[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28435\n",
            "           1       0.83      0.63      0.72        46\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.91      0.82      0.86     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n",
            "[[28429     6]\n",
            " [   17    29]]\n",
            "----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.86      0.57      0.69        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.93      0.79      0.84     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "[[56855     9]\n",
            " [   42    56]]\n",
            "----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85307\n",
            "           1       0.88      0.62      0.73       136\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.94      0.81      0.86     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "[[85295    12]\n",
            " [   51    85]]\n",
            "----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    113732\n",
            "           1       0.89      0.60      0.72       191\n",
            "\n",
            "    accuracy                           1.00    113923\n",
            "   macro avg       0.95      0.80      0.86    113923\n",
            "weighted avg       1.00      1.00      1.00    113923\n",
            "\n",
            "[[113718     14]\n",
            " [    76    115]]\n",
            "----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    142158\n",
            "           1       0.89      0.59      0.71       246\n",
            "\n",
            "    accuracy                           1.00    142404\n",
            "   macro avg       0.94      0.79      0.85    142404\n",
            "weighted avg       1.00      1.00      1.00    142404\n",
            "\n",
            "[[142140     18]\n",
            " [   101    145]]\n",
            "----------\n",
            "----------\n",
            "Logistic Regression at 10% split:\n",
            "Accuracy score = 0.9991924440855307\n",
            "Precision score = 0.8285714285714286\n",
            "Recall score = 0.6304347826086957\n",
            "AUC_ROC score = 0.8151118875237958\n",
            "Balanced accuracy score = 0.8151118875237957\n",
            "F1 score = 0.7160493827160495\n",
            "----------\n",
            "Logistic Regression at 20% split:\n",
            "Accuracy score = 0.9991046662687406\n",
            "Precision score = 0.8615384615384616\n",
            "Recall score = 0.5714285714285714\n",
            "AUC_ROC score = 0.7856351495297049\n",
            "Balanced accuracy score = 0.7856351495297049\n",
            "F1 score = 0.6871165644171779\n",
            "----------\n",
            "Logistic Regression at 30% split:\n",
            "Accuracy score = 0.9992626663389628\n",
            "Precision score = 0.8762886597938144\n",
            "Recall score = 0.625\n",
            "AUC_ROC score = 0.812429665795304\n",
            "Balanced accuracy score = 0.8124296657953041\n",
            "F1 score = 0.7296137339055795\n",
            "----------\n",
            "Logistic Regression at 40% split:\n",
            "Accuracy score = 0.9992099927143773\n",
            "Precision score = 0.8914728682170543\n",
            "Recall score = 0.6020942408376964\n",
            "AUC_ROC score = 0.8009855722178142\n",
            "Balanced accuracy score = 0.8009855722178142\n",
            "F1 score = 0.71875\n",
            "----------\n",
            "Logistic Regression at 50% split:\n",
            "Accuracy score = 0.9991643493160305\n",
            "Precision score = 0.8895705521472392\n",
            "Recall score = 0.5894308943089431\n",
            "AUC_ROC score = 0.7946521373161226\n",
            "Balanced accuracy score = 0.7946521373161226\n",
            "F1 score = 0.7090464547677262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIAnfhgXR96n",
        "colab_type": "text"
      },
      "source": [
        "The balanced accuracy scores from the above reuslts are following a random trend. There is increase and then decrease after increasing the test size. Moreover, the accuracy of each of these models is almost a perfect score (100%). \n",
        "\n",
        "On the basis of these results, we can conclude that the model is overfitted and is not suitable for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDhJHyU0Solq",
        "colab_type": "text"
      },
      "source": [
        "Also, from the above results, we can say that almost every new transaction that needs classification will have a higher probability of getting classified as a legitimate transaction. This is due to the high imbalance of the training dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VhDPJH9TYba",
        "colab_type": "text"
      },
      "source": [
        "To overcome this issue, we need to bring the data of the fraudulent and non-fradulent transactions to equal or almost equal percentages.\n",
        "\n",
        "As we cannot generate fraud data, Under Sampling is performed.\n",
        "\n",
        "The results of Logistic Regression on Under Sampled data is analyzed in a different file. Please find the file in the submission."
      ]
    }
  ]
}